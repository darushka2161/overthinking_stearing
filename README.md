# overthinking_stearing
Crosscoders and Model Tracing
# Отчет по эксперименту: Сложение дробей с использованием стиринга в DEEPSEEK-R1-LLAMA-8B

## Цель исследования
Исследовать влияние стиринга (steering) на качество выполнения арифметических операций с дробями в модели DEEPSEEK-R1-LLAMA-8B.

## Методология
1. **Генерация датасета**: Создан датасет из 10 примеров сложения дробей с разными знаменателями (включая отрицательные дроби).
2. **API Neuronpedia**: Использован API для взаимодействия с моделью и применения стиринга к определенному нейрону (`30939` в слое `15-llamascope-slimpj-res-32k`).
3. **Параметры стиринга**: Проверены значения силы стиринга от -10 до 50.
4. **Оценка точности**: Результаты модели сравнивались с правильными ответами с помощью точного сравнения дробей.

## Результаты
### Точность без стиринга
- **Baseline accuracy**: 0/10 (0%) - модель не смогла правильно решить ни одного примера без стиринга.

### Точность при разных уровнях стиринга
| Strength | Correct Answers | Accuracy |
|----------|-----------------|----------|
| -10      | 0               | 0%       |
| -7       | 3               | 30%      |
| -3       | 2               | 20%      |
| -5       | 1               | 10%      |
| -2       | 1               | 10%      |
| -1       | 0               | 0%       |
| 1        | 0               | 0%       |
| 2        | 0               | 0%       |
| 5        | 0               | 0%       |
| 10       | 0               | 0%       |
| 50       | 0               | 0%       |


## Ключевые наблюдения
1. **Оптимальный стиринг**: Лучшие результаты (30% accuracy) достигнуты при силе стиринга -7.
2. **Отрицательный стиринг**: Эффективен только в узком диапазоне (-7...-3), при дальнейшем уменьшении сила эффекта снижается.
3. **Положительный стиринг**: Не показал улучшения качества на этой задаче.
4. **Ограничения модели**:
   - Даже с оптимальным стирингом точность не превысила 30%
   - Модель часто прерывает вычисления из-за ограничения на длину ответа (128 токенов)

## Выводы
Стиринг может улучшить выполнение арифметических операций в LLM, но:
- Требует точной настройки параметров
- Дает нестабильные результаты
- Сильно зависит от конкретной задачи
- Не устраняет фундаментальные ограничения модели на точные вычисления

Рекомендации для будущих исследований:
1. Увеличение лимита токенов для полного вывода вычислений
